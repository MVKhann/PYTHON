{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Classify language out of the list given below using just stop words. Remove punctuations, make lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'bengali',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "from nltk.text import Text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "dict_lang = {}\n",
    "languages = stopwords.fileids()\n",
    "puncts = string.punctuation\n",
    "li=[]\n",
    "def q1(str1):\n",
    "    token = word_tokenize(str1)\n",
    "    for i in languages:\n",
    "        dict_lang[i]=0\n",
    "        stop = set(stopwords.words(i))\n",
    "        for tok in token:\n",
    "            if (tok.lower() in stop) and (tok not in li) and (i in dict_lang) and (tok not in puncts):\n",
    "                    dict_lang[i]+=1\n",
    "                    li.append(tok)\n",
    "        li=[]\n",
    "\n",
    "    return dict_lang\n",
    "    \n",
    "# output = (q1(\"An article is qualunque member van un class of dedicated words naquele estão used with noun phrases per mark the identifiability of the referents of the noun phrases\"))\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test=\"An article is qualunque member van un class of dedicated words naquele estão used with noun phrases per mark the identifiability of the referents of the noun phrases\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output:\n",
    "{'arabic': 0,\n",
    " 'azerbaijani': 1,\n",
    " 'danish': 0,\n",
    " 'dutch': 3,\n",
    " 'english': 5,\n",
    " 'finnish': 0,\n",
    " 'french': 1,\n",
    " 'german': 1,\n",
    " 'greek': 0,\n",
    " 'hungarian': 1,\n",
    " 'indonesian': 1,\n",
    " 'italian': 2,\n",
    " 'kazakh': 0,\n",
    " 'nepali': 0,\n",
    " 'norwegian': 0,\n",
    " 'portuguese': 1,\n",
    " 'romanian': 1,\n",
    " 'romanurdu': 1,\n",
    " 'russian': 0,\n",
    " 'slovene': 0,\n",
    " 'spanish': 1,\n",
    " 'swedish': 0,\n",
    " 'tajik': 0,\n",
    " 'turkish': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arabic': 0, 'azerbaijani': 1, 'bengali': 0, 'danish': 0, 'dutch': 3, 'english': 5, 'finnish': 0, 'french': 1, 'german': 1, 'greek': 0, 'hungarian': 1, 'indonesian': 1, 'italian': 2, 'kazakh': 0, 'nepali': 0, 'norwegian': 0, 'portuguese': 1, 'romanian': 1, 'russian': 0, 'slovene': 0, 'spanish': 1, 'swedish': 0, 'tajik': 0, 'turkish': 0}\n"
     ]
    }
   ],
   "source": [
    "print(q1(Test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Make a Roman urdu sentence tokenizer by assuming that there will be no (.full stop) and (? question mark) in the end of sentence. Make some rules to made that tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lekin', 'daad', 'dainee', 'padtee', 'hai', 'snatkaron', 'ko', 'jo', 'aisay', 'bohat', 'se', 'digrmsayl', 'ki', 'terhan', 'is', 'maslay', 'ka', 'hal', 'nikaalte', 'mein', 'bhi', 'kamyaab', 'ho', 'gaye', 'hain', 'ghair', 'mulki', 'tehqeeqi', 'jareeday', 'fiction', 'mein', 'shaya', 'honay', 'wali', 'report', 'ke', 'mutabiq', 'snatkaron', 'nay', 'aik', 'aisi', 'battery', 'tayaar', 'karli', 'hai', 'jisay', 'saal', 'mein', 'sirf', '1', 'baar', 'charge', 'karna', 'parre', 'ga', 'magar', 'yeh', 'battery', 'kamray', 'ke', 'daraja', 'hararat', 'mein', 'behtareen', 'kaam', 'kere', 'gi', 'is', 'aylominim', 'ion', 'battery', 'ko', 'jet', 'laboratory', 'larns', 'national', 'laboratory', 'Nasa', 'hnda', 'reserch', 'insti', 'tute', 'ke', 'mahireen', 'par', 'mushtamil', 'team', 'naay', 'tayyar', 'kya', 'hai', 'jisay', 'aik', 'karne', 'ke', 'baad', 'taqreeban', '10', 'Mahtaq', 'dobarah', 'charge', 'karne', 'ki', 'zaroorat', 'nahi', 'rehti', 'hai', 'tehqeeqi', 'team', 'ke', 'sarbarah', 'aur', '2008', 'hamza', 'mein', 'noble', 'inaam', 'haasil', 'karne', 'walay', 'chemiya', 'ke', 'professor', 'Robert', 'grbs', 'ne', 'bataya', 'ke', 'aylominim', 'ion', 'battery', 'murawaja', 'batrion', 'ke', 'muqablay', 'mein', '20', 'gina', 'taaqat', 'war', 'hoti', 'hain', 'aur', 'inhen', '10', 'mah', 'taq', 'charge', 'karne', 'ki', 'zaroorat', 'nahi', 'padtee', 'ha', 'team', 'ke', 'sarbarah', 'professor', 'Robert', 'grace', 'ke', 'mutabiq', 'aam', 'istemaal', 'ki', 'jany', 'wali', 'batrion', 'ke', 'muqablay', 'main', 'zyada', 'achi', 'h']\n",
      "['lekin daad dainee padtee hai ', 'snatkaron ko jo aisay bohat se digrmsayl ki terhan is maslay ka hal nikaalte mein bhi kamyaab ho gaye hain ', 'ghair mulki tehqeeqi jareeday fiction mein shaya honay wali report ke mutabiq snatkaron nay aik aisi battery tayaar karli hai ', 'jisay saal mein sirf 1 baar charge karna parre ga magar yeh battery kamray ke daraja hararat mein behtareen kaam kere gi ', 'is aylominim ion battery ko jet laboratory larns national laboratory Nasa hnda reserch insti tute ke mahireen par mushtamil team naay tayyar kya hai ', 'jisay aik karne ke baad taqreeban 10 Mahtaq dobarah charge karne ki zaroorat nahi rehti hai ', 'tehqeeqi team ke sarbarah aur 2008 hamza mein noble inaam haasil karne walay chemiya ke professor Robert grbs ne bataya ke aylominim ion battery murawaja batrion ke muqablay mein 20 gina taaqat war hoti hain ', 'aur inhen 10 mah taq charge karne ki zaroorat nahi padtee ha ', 'team ke sarbarah professor Robert grace ke mutabiq aam istemaal ki jany wali batrion ke muqablay main zyada achi h ']\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "from nltk.text import Text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import string\n",
    "\n",
    "punct = string.punctuation\n",
    "\n",
    "def q2(str1):\n",
    "    tok = []\n",
    "    sents = []\n",
    "    index=0\n",
    "    tokens = word_tokenize(str1)\n",
    "    for i in tokens:\n",
    "        if i not in punct:\n",
    "            tok.append(i)\n",
    "#     print(tok)\n",
    "    size = len(tok)\n",
    "    tok.append(\" \")\n",
    "    li=[\"aur\",\"jo\",\"magar\",\"lekin\",\"jisay\"]\n",
    "    for k in range(size):\n",
    "        s = \"\"\n",
    "        if (tok[k]==\"h\" or tok[k]==\"ha \" or tok[k]==\"hai\" or tok[k]==\"hain\" or tok[k]==\"ge\" or tok[k]==\"gi\"):\n",
    "            if(tok[k+1] not in li):\n",
    "                for j in range(index,k+1):\n",
    "                    s += tok[j]\n",
    "                    s+=\" \"\n",
    "                sents.append(s)\n",
    "                index = k+1\n",
    "    return(sents)\n",
    "    \n",
    "\n",
    "Test2=\"lekin daad dainee padtee hai snatkaron ko jo aisay bohat se digrmsayl ki terhan is maslay ka hal nikaalte mein bhi kamyaab ho gaye hain ghair mulki tehqeeqi jareeday fiction mein shaya honay wali report ke mutabiq snatkaron nay aik aisi battery tayaar karli hai jisay saal mein sirf 1 baar charge karna parre ga magar yeh battery kamray ke daraja hararat mein behtareen kaam kere gi is aylominim ion battery ko jet laboratory, larns national laboratory Nasa , hnda reserch insti tute ke mahireen par mushtamil team naay tayyar kya hai jisay aik karne ke baad taqreeban 10 Mahtaq dobarah charge karne ki zaroorat nahi rehti hai tehqeeqi team ke sarbarah aur 2008 hamza mein noble inaam haasil karne walay chemiya ke professor Robert  grbs ne bataya ke aylominim ion battery murawaja batrion ke muqablay mein 20 gina taaqat war hoti hain aur inhen 10 mah taq charge karne ki zaroorat nahi padtee ha team ke sarbarah professor Robert grace ke mutabiq aam istemaal ki jany wali batrion ke muqablay main zyada achi h\"\n",
    "output = q2(Test2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test2=\"lekin daad dainee padtee hai snatkaron ko jo aisay bohat se digrmsayl ki terhan is maslay ka hal nikaalte mein bhi kamyaab ho gaye hain ghair mulki tehqeeqi jareeday fiction mein shaya honay wali report ke mutabiq snatkaron nay aik aisi battery tayaar karli hai jisay saal mein sirf 1 baar charge karna parre ga magar yeh battery kamray ke daraja hararat mein behtareen kaam kere gi is aylominim ion battery ko jet laboratory, larns national laboratory Nasa , hnda reserch insti tute ke mahireen par mushtamil team naay tayyar kya hai jisay aik karne ke baad taqreeban 10 Mahtaq dobarah charge karne ki zaroorat nahi rehti hai tehqeeqi team ke sarbarah aur 2008 hamza mein noble inaam haasil karne walay chemiya ke professor Robert  grbs ne bataya ke aylominim ion battery murawaja batrion ke muqablay mein 20 gina taaqat war hoti hain aur inhen 10 mah taq charge karne ki zaroorat nahi padtee ha team ke sarbarah professor Robert grace ke mutabiq aam istemaal ki jany wali batrion ke muqablay main zyada achi h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Sample: \"lekin daad dainee padtee hai snatkaron ko jo aisay bohat se digrmsayl ki terhan is maslay ka hal nikaalte mein bhi kamyaab ho gaye hain\", \"ghair mulki tehqeeqi jareeday fiction mein shaya honay wali report ke mutabiq snatkaron nay aik aisi battery tayaar karli hai jisay saal mein sirf 1 baar charge karna parre ga magar yeh battery kamray ke daraja hararat mein behtareen kaam kere gi\", \"is aylominim ion battery ko jet laboratory, larns national laboratory Nasa , hnda reserch insti tute ke mahireen par mushtamil team naay tayyar kya hai\", \"jisay aik karne ke baad taqreeban 10 Mah taq dobarah charge karne ki zaroorat nahi rehti hai\", \"tehqeeqi team ke sarbarah aur 2008 hamza mein noble inaam haasil karne walay chemiya ke professor Robert  grbs ne bataya ke aylominim ion battery murawaja batrion ke muqablay mein 20 gina taaqat war hoti hain aur inhen 10 mah taq charge karne ki zaroorat nahi padtee ha\", \"team ke sarbarah professor Robert grace ke mutabiq aam istemaal ki jany wali batrion ke muqablay main zyada achi h\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: Find the longest word in Test2 and that word's length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laboratory   10\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "from nltk.text import Text\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def q3(str1):\n",
    "    maxim = \"\"\n",
    "    tokens = word_tokenize(str1)\n",
    "#     maxim = max(tokens)\n",
    "    for tok in tokens:\n",
    "        if len(tok) >= len(maxim):\n",
    "            maxim = tok\n",
    "    print(maxim,\" \",len(maxim))\n",
    "\n",
    "Test2=\"lekin daad dainee padtee hai snatkaron ko jo aisay bohat se digrmsayl ki terhan is maslay ka hal nikaalte mein bhi kamyaab ho gaye hain ghair mulki tehqeeqi jareeday fiction mein shaya honay wali report ke mutabiq snatkaron nay aik aisi battery tayaar karli hai jisay saal mein sirf 1 baar charge karna parre ga magar yeh battery kamray ke daraja hararat mein behtareen kaam kere gi is aylominim ion battery ko jet laboratory, larns national laboratory Nasa , hnda reserch insti tute ke mahireen par mushtamil team naay tayyar kya hai jisay aik karne ke baad taqreeban 10 Mahtaq dobarah charge karne ki zaroorat nahi rehti hai tehqeeqi team ke sarbarah aur 2008 hamza mein noble inaam haasil karne walay chemiya ke professor Robert  grbs ne bataya ke aylominim ion battery murawaja batrion ke muqablay mein 20 gina taaqat war hoti hain aur inhen 10 mah taq charge karne ki zaroorat nahi padtee ha team ke sarbarah professor Robert grace ke mutabiq aam istemaal ki jany wali batrion ke muqablay main zyada achi h\"\n",
    "q3(Test2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: Rule Based Roman Urdu Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roman Urdu lacks standard lexicon and usually many spelling variations exist for a given word, e.g., the word\n",
    "zindagi (life) is also written as zindagee, zindagy, zaindagee and zndagi. So, in this question you have to Normalize Roman Urdu words using the following Rules given in the attached Pdf. Your Code works for a complete Sentence or multiple sentences.\n",
    "\n",
    "For Example: zaroori, zaruri, zarori map to the 'zrory'. So zrory becomes the correct word for all representations mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zrory , zrory , zrory \n",
      "zindagee , zindagy , zaendagie and zndagy \n"
     ]
    }
   ],
   "source": [
    "#normalization practice\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def normalize(str1):\n",
    "    st = \"\"\n",
    "    token = word_tokenize(str1)\n",
    "    for tok in word_tokenize(str1):\n",
    "        tok = tok.lower()\n",
    "    for i in token:\n",
    "        li = list(i)\n",
    "        for j in range(len(li)-1):\n",
    "            size = len(li)\n",
    "            if li[size-1]=='n' and li[size-2]=='i' and li[size-3]=='a': ############replace ain with ein\n",
    "                li[size-3]='e'\n",
    "                \n",
    "            elif (j!=0) and (li[j]=='a' and li[j+1]=='r'): #############replace ar with r except for the start\n",
    "                li[j+1]='r'\n",
    "                li[j] = \"*\"\n",
    "                \n",
    "            elif li[j]=='a' and li[j+1]=='i': #############replace ai with ae \n",
    "                li[j+1]='e'\n",
    "                \n",
    "            elif li[j]=='i' and li[j+1]=='y': ###########3#iy with I (multiple ys)\n",
    "                li[j]='I'\n",
    "                k=j+1\n",
    "                while li[k]=='y' and k != len(li)-1:\n",
    "                    li[k]=\"*\"\n",
    "                    k+=1\n",
    "                    \n",
    "            elif li[size-1]=='y' and li[size-2]=='a': #############ay to e\n",
    "                li[size-2]='e'\n",
    "                li[size-1]='*'\n",
    "                \n",
    "            elif li[j]=='h' and li[j+1]=='i' : #########3#ih to e with multiple h\n",
    "                li[j]='e'\n",
    "                k = j+1\n",
    "                while li[k]=='h' and k != len(li)-1:\n",
    "                    li[k]=\"*\"\n",
    "                    k+=1\n",
    "                    \n",
    "            elif li[size-1]=='y' and li[size-2]=='e': ############ey to e\n",
    "                li[size-2]='e'\n",
    "                li[size-1]='*'\n",
    "                \n",
    "            elif li[j]=='s' and li[j+1]=='s': ###############ssssss to s\n",
    "                li[j]='s'\n",
    "                k = j+1\n",
    "                while li[k]=='s' and k != len(li)-1:\n",
    "                    li[k]=\"*\"\n",
    "                    k+=1\n",
    "                    \n",
    "            elif li[size-1]=='e' and li[size-2]=='i': #################ie to y\n",
    "                li[size-2]='y'\n",
    "                li[size-1]='*'\n",
    "                \n",
    "            elif (j!=size-2) and (li[j]=='r' and li[j+1]=='y'): ############3ry with ri except at the end\n",
    "                li[j+1]='i'\n",
    "                \n",
    "            elif li[0]=='e' and li[1]=='s': ###########es with is\n",
    "                li[0]='i'\n",
    "                \n",
    "            elif (j!=size-2) and (li[j]=='s' and li[j+1]=='y'): ###########3#sy with si except at the end\n",
    "                li[j+1]='i'\n",
    "                \n",
    "            elif li[j]=='a' and li[j+1]=='a': #############aaa to a\n",
    "                li[j]='a'\n",
    "                k = j+1\n",
    "                while li[k]=='a' and k != len(li)-1:\n",
    "                    li[k]=\"*\"\n",
    "                    k+=1\n",
    "\n",
    "            elif (j!=size-2) and (li[j]=='t' and li[j+1]=='y'): ###########ty with ti except at the end\n",
    "                li[j+1]='i'\n",
    "                \n",
    "            elif li[j]=='j' and li[j+1]=='j': ###########jjjjj to j\n",
    "                li[j]='j'\n",
    "                k = j+1\n",
    "                while li[k]=='j' and k != len(li)-1:\n",
    "                    li[k]=\"*\"\n",
    "                    k+=1\n",
    "\n",
    "            elif li[j]=='o' and li[j+1]=='o': #############oooo to o\n",
    "                li[j]='o'\n",
    "                k = j+1\n",
    "                while li[k]=='o' and k != len(li)-1:\n",
    "                    li[k]=\"*\"\n",
    "                    k+=1\n",
    "\n",
    "            elif li[j-1] == 'e' and li[j-2]=='e' and li[j]=='e' and li[j+1]=='e': ############eeee to i\n",
    "                li[j-2]='i'\n",
    "                k = j-1\n",
    "                while li[k]=='e' and k != len(li)-1:\n",
    "                    li[k]=\"*\"\n",
    "                    k+=1\n",
    "            elif li[size-1]=='i' and (li[size-2]>='b' and li[size-2]<='z'): ###############i to y if preceeded by\n",
    "                li[size-1]='y'\n",
    "                \n",
    "            elif li[j]=='d' and li[j+1]=='d': ##############ddd to d\n",
    "                li[j]='d'\n",
    "                k = j+1\n",
    "                while li[k]=='d' and k != len(li)-1:\n",
    "                    li[k]=\"*\"\n",
    "                    k+=1\n",
    "                \n",
    "            elif li[j]=='u': #####################u to o\n",
    "                li[j]='o'\n",
    "\n",
    "            elif li[j]=='h' and (li[j-1] == 'a' or  li[j-1] == 'c' or li[j-1] == 'e' or (li[j-1] >= 'f' and li[j-1] <= 'j') or (li[j-1] >= 'l' and li[j-1] <= 'o') or (li[j-1] >= 'q' or li[j-1] <= 'z') ): #remove h if preceeded by acefghijlmnoqrstuvwxyz\n",
    "                li[j]='*'\n",
    "            i = \"\"\n",
    "            for k in li:\n",
    "                if k != \"*\":\n",
    "                    i+=k\n",
    "        st+=i\n",
    "        st+=\" \"\n",
    "    print(st)\n",
    "\n",
    "# normalize(\"I am wisal stain arnaaaajjjdard hhi am aaia fdsiyyyyk howay from ryoory Pakissssstanry esff dddd ajjihhhhh\")\n",
    "\n",
    "# normalize(\"india dunya ki sab se achi cricket team hai,pakistan un k samne kuch nahi\")\n",
    "\n",
    "normalize(\"zaroori,zaruri,zarori\")\n",
    "normalize(\"zindagee, zindagy, zaindageeee and zndagi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
